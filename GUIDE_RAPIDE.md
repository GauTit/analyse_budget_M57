# Guide Rapide - G√©n√©ration de Rapport Budg√©taire

## üöÄ D√©marrage rapide (3 √©tapes)

### 1. Installer les d√©pendances

```bash
pip install pandas odfpy reportlab matplotlib python-docx openai
```

### 2. Configurer la cl√© API OpenAI

**Windows PowerShell** :
```powershell
$env:OPENAI_API_KEY = "votre-cle-api-ici"
```

**Windows CMD** :
```cmd
set OPENAI_API_KEY=votre-cle-api-ici
```

### 3. Lancer le workflow automatique

```bash
python workflow_complet.py
```

Le script vous guidera pour choisir entre :
- Rapport mono-ann√©e
- Rapport multi-ann√©es

Et g√©n√©rera automatiquement **tout** de A √† Z ! üéâ

---

## üìÅ Fichiers g√©n√©r√©s

### Rapport mono-ann√©e
- `output/donnees_enrichies.json` - Donn√©es enrichies avec ratios
- `PROMPTS_RAPPORT_COMPLET_ENRICHIS.xlsx` - Prompts et r√©ponses
- `output/rapport_analyse_mono_annee.pdf` - Rapport PDF final
- `output/rapport_analyse_mono_annee.docx` - Rapport Word final

### Rapport multi-ann√©es
- `output/donnees_multi_annees.json` - Donn√©es multi-ann√©es
- `PROMPTS_RAPPORT_COMPLET_ENRICHIS.xlsx` - Prompts et r√©ponses
- `output/rapport_analyse_multi_annees.pdf` - Rapport PDF final
- `output/rapport_analyse_multi_annees.docx` - Rapport Word final

---

## ‚öôÔ∏è Configuration avanc√©e

### Modifier le mod√®le OpenAI

√âditez `generer_reponses_avec_openai.py` :

```python
MODEL = "gpt-4.1-mini"  # Par d√©faut
# Ou utilisez :
# MODEL = "gpt-4-turbo"
# MODEL = "gpt-3.5-turbo"
```

### Modifier la temp√©rature (cr√©ativit√©)

```python
TEMPERATURE = 0.7  # Par d√©faut (0.0 = d√©terministe, 1.0 = cr√©atif)
```

### Modifier la longueur des r√©ponses

```python
MAX_TOKENS = 2000  # Par d√©faut
```

---

## üîß D√©pannage

### ‚ùå "OPENAI_API_KEY not found"
‚Üí V√©rifiez que la variable d'environnement est bien configur√©e

### ‚ùå "Rate limit exceeded"
‚Üí Augmentez `DELAI_ENTRE_REQUETES` dans `generer_reponses_avec_openai.py`

### ‚ùå "Model not found: gpt-4.1-mini"
‚Üí V√©rifiez que le mod√®le existe ou changez pour `gpt-4-turbo` ou `gpt-3.5-turbo`

### ‚ùå R√©ponses tronqu√©es
‚Üí Augmentez `MAX_TOKENS` dans `generer_reponses_avec_openai.py`

---

## üí∞ Estimation des co√ªts

Pour GPT-4.1 mini :
- ~20-30 prompts par rapport
- ~500 tokens par prompt
- ~500 tokens par r√©ponse
- **Co√ªt total : quelques centimes** par rapport complet

Pour GPT-4-turbo :
- **Co√ªt total : quelques dizaines de centimes** par rapport complet

---

## üìö Documentation compl√®te

Consultez [README_OPENAI.md](README_OPENAI.md) pour :
- Workflow manuel √©tape par √©tape
- Liste compl√®te des mod√®les disponibles
- Configuration d√©taill√©e
- Exemples d'utilisation avanc√©e
